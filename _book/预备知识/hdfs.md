# hdfs学习笔记

### 一、HDFS架构及读写流程

#### 1.Hadoop架构：

![img](file:///C:/Users/lv/AppData/Local/Temp/msohtmlclip1/01/clip_image002.jpg)

![img](file:///C:/Users/lv/AppData/Local/Temp/msohtmlclip1/01/clip_image004.jpg)




#### 2.HDFS写文件的原理：

![img](file:///C:/Users/lv/AppData/Local/Temp/msohtmlclip1/01/clip_image006.jpg)

1）客户端通过Distributed FileSystem模块向NameNode请求上传文件，NameNode检查目标文件是否已存在，父目录是否存在。

2）NameNode返回是否可以上传。

3）客户端请求第一个 Block上传到哪几个DataNode服务器上。

4）NameNode返回3个DataNode节点，分别为dn1、dn2、dn3。

5）客户端通过FSDataOutputStream模块请求dn1上传数据，dn1收到请求会继续调用dn2，然后dn2调用dn3，将这个通信管道建立完成。

6）dn1、dn2、dn3逐级应答客户端。

7）客户端开始往dn1上传第一个Block（先从磁盘读取数据放到一个本地内存缓存），以Packet为单位，dn1收到一个Packet就会传给dn2，dn2传给dn3；dn1每传一个packet会放入一个应答队列等待应答。

8）当一个Block传输完成之后，客户端再次请求NameNode上传第二个Block的服务器。（重复执行3-7步）。



#### 3.HDFS读文件的原理：

![img](file:///C:/Users/lv/AppData/Local/Temp/msohtmlclip1/01/clip_image008.jpg)

1）客户端通过Distributed FileSystem向NameNode请求下载文件，NameNode通过查询元数据，找到文件块所在的DataNode地址。

2）挑选一台DataNode（就近原则，然后随机）服务器，请求读取数据。

3）DataNode开始传输数据给客户端（从磁盘里面读取数据输入流，以Packet为单位来做校验）。

4）客户端以Packet为单位接收，先在本地缓存，然后写入目标文件。





### 二、HDFS细节问题

#### 1.HDFS的块大小设置问题
##### （1）小文件的Block占用
  小于块大小的小文件不会占用整个HDFS块空间。也就是说，较多的小文件会占用更多的NameNode内
存（记录了文件的位置等信息）；也即，在文件处理时，可能会有较大的网络开销（频繁与namenode交互）。
##### （2）块大小的设置依据
在HDFS里面，DataNode上的块大小默认是64MB(1.x版本)或128MB(2.x版本)。
为什么要选择64M或128M？
##### 第一个问题：为什么不能远远小于64M或128M
- 减少硬盘寻道时间
    HDFS设计前提是支持大容量的流式数据操作，所以即使是一般的数据读写操作，涉及到的数据量都是比较大的。假如数据块大小设置过小，那需要读取的数据块就比较多；由于数据块在硬盘上非连续存储，普通硬盘因为需要移动磁头，所以随机寻址较慢，读越多的数据块就越增大了总的硬盘寻道时间。当硬盘寻道时间比IO时间还要长的多时，那么硬盘寻道时间就成了系统的一个瓶颈。因此设置合适的块大小有助于减少硬盘寻道时间，提高系统吞吐量。
- 减少Namenode内存消耗
    对于HDFS系统来说，它只有一个NameNode节点，它的内存是有限的。然而，NameNode需要在其内存FSImage文件中中记录存储在DataNode中的数据块信息，假如数据块大小设置的过小，需要维护的数据块信息就会增多，那NameNode的内存可能就会不够用。
##### 第二个问题：为什么不能远大于64M或128M
主要从上层的MapReduce框架来讨论
+ Map崩溃问题
    系统需要重新启动，启动过程需要重新加载数据，数据块越大，数据加载时间越长，系统恢复过程越长
+ 监管时间问题
    主节点监管其他节点的情况，每个节点会周期性的把完成的工作和状态的更新报告回来。如果一个节点保持沉默超过一个预设的时间间隔，主节点记录下这个节点状态为死亡，并把分配给这个节点的数据发到别的节点。对于这个“预设的时间间隔”，这是从数据块的角度大概估算的。假如是对于64MB的数据块，可以假设是10分钟之内无论怎样也能有反应，超过10分钟也没反应，那就是死了。可对于640MB或是1G以上的数据，应该要估算个多长的时间？估算的时间短了，那就误判死亡了，分分钟更坏的情况是所有节点都会被判死亡。估算的时间长了，那等待的时间就过长了。所以对于过大的数据块，这个“预设的时间间隔”不好估算。
+ 问题分解问题
    数据量大小是问题解决的复杂度是成线性关系的。对于同个算法，处理的数据量越大，它的时间复杂度也就越大。
+ 约束Map输出
    在Map Reduce框架里，Map之后的数据是要经过排序才执行Reduce操作的。这里的排序，先对小文件进行排序，然后将小文件归并成大文件，块设置的过大就会使时间复杂度变高。
##### Hadoop权威指南中的解释
        HDFS的块比磁盘块大，其目的是为了最小化寻址开销。如果块设置得足够大，从磁盘传输数据的时间可以明显大于定位这个块开始位置所需的时间。这样，传输一个由多个块组成的文件的时间取决于磁盘传输速率。
        我们来做一个速算，如果寻址时间为10ms左右，而传输速率为100MB/s，为了使寻址时间仅占传输时间的1%，我们需要设置块大小为100MB左右。而默认的块大小实际为64MB，但是很多情况下HDFS使用128MB的块设置。以后随着新一代磁盘驱动器传输速率的提升，块的大小将被设置得更大。  
        但是该参数也不会设置得过大。MapReduce中的map任务通常一次处理一个块中的数据，因此如果任务数太少（少于集群中的节点数量），作业的运行速度就会比较慢。
##### (3) hdfs修改块大小
修改hdfs-site.xml配置文件，配置全局参数dfs.block.size,单位为Byte（字节）
```       
         <property>
                 <name>dfs.block.size</name>
                 <value>512000</value>
         </property>
```
**注意：blockSize必须是io.bytes.per.checksum(512)的整数倍，否则会报错 **

-----------------------------------------------------------------------------

#### 2. HDFS的写入流程中相关问题
##### （1）客户端向hdfs写入数据的流程
1. 客户端（fs）向namenode请求上传文件，namenode检查目标文件是否已存在，父目录是否存在。若通过检查，直接先将操作写入
2. namenode返回是否可以上传，即返回输出流对象
3. 客户端按照预设的块大小切分文件，并向namenode请求第一个 block上传到哪几个datanode服务器上
4. namenode返回3个datanode节点，分别为dn1、dn2、dn3。
5. 客户端将namenode返回的分配的可写的datanode列表发送给最近的第一个datanode节点，假如是dn1，则dn1收到请求会继续调用dn2，然后dn2调用dn3，(本质上是一个RPC调用，建立pipeline)将这个通信管道建立完成
6. dn1、dn2、dn3逐级应答客户端通信管道建立完成
7. 客户端开始往dn1上传第一个block，以packet为单位，dn1收到一个packet就会传给dn2，dn2传给dn3
8. 当一个block传输完成之后，客户端再次请求namenode上传第二个block的服务器。（重复执行3-7步）
9. 所有块传输完成之后，关闭输输出流。
10. 发送完成信号给NameNode。（注：发送完成信号的时机取决于集群是强一致性还是最终一致性，强一致性则需要所有DataNode写完后才向NameNode汇报。最终一致性则其中任意一个DataNode写完后就能单独向NameNode汇报，HDFS一般情况下都是强调强一致性）
##### (2) 写入过程中的要点（三个副本写数据顺序，是同步异步？）
***1. 实际客户端只上传一个datanode，其余两个是托管给HDFS系统，由namenode监督完成的，让datenote自己复制的。然后复制完成以后逐级返回结果给namenode。如果2,3datanode复制失败，再由namenode分配新的datanode地址进行数据块的复制。对于客户端来说默认上传一个datanode就可以了，其余的由datanode自己复制。***
***2. datanode第二三个副本的上传和第一个上传是异步的。***
***3. HDFS 的client端实现了对 HDFS 文件内容的校验和 (checksum) 检查。当客户端创建一个新的HDFS文件时候，分块后会计算这个文件每个数据块的校验和，此校验和会以一个隐藏文件形式保存在同一个 HDFS 命名空间下。当client端从HDFS中读取文件内容后，它会检查分块时候计算出的校验和（隐藏文件里）和读取到的文件块中校验和是否匹配，如果不匹配，客户端可以选择从其他 Datanode 获取该数据块的副本。***

##### （3）hdfs读写实例详细流程的参考
[参考博客](https://blog.51cto.com/hmtk520/1943976)

